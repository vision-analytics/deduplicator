{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import hashlib\n",
    "import time\n",
    "import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status(text):\n",
    "    \"\"\"Function to print and update text on jupyter notebook\n",
    "        Args: \n",
    "            text: str\n",
    "        Returns: \n",
    "    \"\"\"\n",
    "    sys.stdout.write(\"{}\\r\".format(text))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_md5(file_name):\n",
    "    return hashlib.md5(open(file_name,'rb').read()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_duplicates(duplicates):\n",
    "    \"\"\"Function to show duplicates\n",
    "            \n",
    "        Args: \n",
    "            duplicates: dict. {'ref_image_path': ['similar_image_path']}\n",
    "\n",
    "        Returns: \n",
    "\n",
    "    \"\"\"\n",
    "    cntr = 0\n",
    "\n",
    "    for key, vals in duplicates.items():\n",
    "        for val in vals:\n",
    "            cntr+=1\n",
    "            img1 = cv2.imread(key) #read reference image\n",
    "            img2 = cv2.imread(val[0]) #read similar image\n",
    "\n",
    "            if img2 is None: #if file could be not read!\n",
    "                print(\"file not found!\")\n",
    "                plt.imshow(img1[:,:,::-1])\n",
    "                plt.show()\n",
    "                continue\n",
    "                \n",
    "            print(\"**\\nref: {} \\nsimilars: {}\\**\".format(key, val))\n",
    "\n",
    "            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0])) #resize images for hconcat\n",
    "            \n",
    "            combined = cv2.hconcat([img1, img2]) #combine images\n",
    "            \n",
    "            #show images\n",
    "            plt.imshow(combined[:,:,::-1])\n",
    "            plt.show()\n",
    "\n",
    "            print(\"*\"*33)\n",
    "    print(\"{} files detected!\".format(cntr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(duplicates, simulate=False):\n",
    "    \"\"\"Function to remove duplicates\n",
    "            \n",
    "        Args: \n",
    "            duplicates: dict. {'ref_image_path': ['similar_image_path']}\n",
    "\n",
    "        Returns: \n",
    "\n",
    "    \"\"\"\n",
    "    cntr = 0\n",
    "\n",
    "    for key, vals in duplicates.items():\n",
    "        for val in vals:\n",
    "            cntr+=1\n",
    "            if not simulate:\n",
    "                os.remove(val[0])\n",
    "    if simulate:\n",
    "        print(\"{} files WILL BE removed\".format(cntr))\n",
    "    else:\n",
    "        print(\"{} files removed\".format(cntr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !set directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "file_list = glob.glob('/home/xyz/*')[:100]\n",
    "####\n",
    "print(\"{} files will be analyzed\".format(len(file_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate md5 for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "md5_list = []\n",
    "#calculate md5 for each file \n",
    "for ind, image_path in tqdm.tqdm_notebook(enumerate(file_list)):\n",
    "    tmp_md5 = calculate_md5(image_path)\n",
    "    \n",
    "    md5_list.append(tmp_md5) #add features to list\n",
    "\n",
    "print(\"it took {:.2f} seconds to build index for {} images\".format(time.time()-start_time, len(file_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze and find duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duplicates = {}\n",
    "processed_items = []\n",
    "\n",
    "occurrences = lambda s, lst: (i for i,e in enumerate(lst) if e == s)\n",
    "\n",
    "for ind, (image_path, tmp_md5) in tqdm.tqdm_notebook(enumerate(zip(file_list,md5_list))):\n",
    "\n",
    "    if image_path in processed_items:\n",
    "        continue\n",
    "    processed_items.append(image_path)\n",
    "\n",
    "    #print(\"querying similar images for {}\".format(image_path))       \n",
    "    \n",
    "    similar_image_inds = list(occurrences(tmp_md5, md5_list))\n",
    "   \n",
    "    for sim_image_ind  in similar_image_inds:\n",
    "        similar_image_path = file_list[sim_image_ind]\n",
    "        \n",
    "        if similar_image_path == image_path or similar_image_path in processed_items:\n",
    "            continue\n",
    "\n",
    "        if image_path in duplicates:\n",
    "            duplicates[image_path].append([similar_image_path])\n",
    "        else:\n",
    "            duplicates[image_path] = []\n",
    "            duplicates[image_path].append([similar_image_path])\n",
    "        processed_items.append(similar_image_path)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_duplicates(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete samples\n",
    "#### !set simulate=False to remove!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_duplicates(duplicates, simulate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
