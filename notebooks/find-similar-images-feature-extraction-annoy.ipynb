{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from modules.AnnoyUtils import AnnoyUtils\n",
    "from modules.FeatureExtractor import FeatureExtractor\n",
    "from modules.utilities import print_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similar_items(similar_items):\n",
    "    \"\"\"Function to show similar_items\n",
    "            \n",
    "        Args: \n",
    "            similar_items: dict. {'ref_image_path': ['similar_image_path', confidence]}\n",
    "\n",
    "        Returns: \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    cntr = 0\n",
    "\n",
    "    for key, vals in similar_items.items():\n",
    "        for val in vals:\n",
    "            cntr+=1\n",
    "            img1 = cv2.imread(key) #read reference image\n",
    "            img2 = cv2.imread(val[0]) #read similar image\n",
    "\n",
    "            if img2 is None: #if file could be not read!\n",
    "                print(\"file not found!\")\n",
    "                plt.imshow(img1[:,:,::-1])\n",
    "                plt.show()\n",
    "                continue\n",
    "                \n",
    "            #score = val[1]\n",
    "            print(\"**\\nref: {} \\nsimilars: {}\\**\".format(key, val))\n",
    "\n",
    "            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0])) #resize images for hconcat\n",
    "            \n",
    "            combined = cv2.hconcat([img1, img2]) #combine images\n",
    "            \n",
    "            #show images\n",
    "            plt.imshow(combined[:,:,::-1])\n",
    "            plt.show()\n",
    "\n",
    "            print(\"*\"*33)\n",
    "    print(\"{} files detected!\".format(cntr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_similar_items(similar_items, simulate=False):\n",
    "    \"\"\"Function to remove similar_items\n",
    "            \n",
    "        Args: \n",
    "            similar_items: dict. {'ref_image_path': ['similar_image_path', confidence]}\n",
    "\n",
    "        Returns: \n",
    "\n",
    "    \"\"\"\n",
    "    cntr = 0\n",
    "\n",
    "    for key, vals in similar_items.items():\n",
    "        for val in vals:\n",
    "            cntr+=1\n",
    "            if not simulate:\n",
    "                os.remove(val[0])\n",
    "    if simulate:\n",
    "        print(\"{} files WILL BE removed\".format(cntr))\n",
    "    else:\n",
    "        print(\"{} files removed\".format(cntr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "image_list = glob.glob('/home/xyz/*')\n",
    "\n",
    "features_list = []\n",
    "\n",
    "annoy_metric = \"angular\" # \"euclidean\", \"manhattan\", \"hamming\", \"dot\"\n",
    "annoy_vector_length = 4096 #feature length (vgg16)\n",
    "annoy_n_trees = 50 #More trees gives higher precision when querying -> https://github.com/spotify/annoy\n",
    "\n",
    "similarity_threshold = 0.1 #0.0 exact match, <0.5 similar images\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"preparing featureExtractor\")\n",
    "feature_extractor = FeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"preparing annoy index for {} images\".format(len(image_list)))\n",
    "\n",
    "#init annoy\n",
    "annoy_utils = AnnoyUtils()\n",
    "annoy_utils.prepare_annoy(annoy_vector_length, annoy_metric)\n",
    "\n",
    "#set image_list\n",
    "\n",
    "annoy_utils.set_image_list(image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  extract features and update annoy index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#batch processing\n",
    "start_time = time.time()\n",
    "\n",
    "total_size = len(image_list)\n",
    "batch_size = 64 #mind the memory usage!\n",
    "\n",
    "ind = 0\n",
    "for start_index in range(0, total_size, batch_size):\n",
    "    end_index = total_size if start_index + batch_size > total_size else start_index + batch_size\n",
    "    batch = image_list[start_index:end_index] \n",
    "    \n",
    "    print_status(\"processing... {}/{}\".format(start_index, total_size))\n",
    "    \n",
    "    batch_features = feature_extractor.extract_feature_for_batch_images(batch)\n",
    "    \n",
    "    for tmp_features in batch_features:\n",
    "        features_list.append(tmp_features) #add features to list\n",
    "        annoy_utils.ann_index.add_item(ind, tmp_features)\n",
    "        ind+=1\n",
    "\n",
    "#print(\"building index..\")\n",
    "annoy_utils.build_index(annoy_n_trees)\n",
    "\n",
    "#print(\"saving index..\")\n",
    "annoy_utils.save_index('annoy.index')\n",
    "\n",
    "print(\"it took {:.2f} seconds to build index for {} images\".format(time.time()-start_time, total_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze and find similar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_items = {}\n",
    "\n",
    "processed_items = []\n",
    "retrieve_n_most_similar=9999\n",
    "\n",
    "for ind, (image_path, tmp_features) in tqdm.tqdm_notebook(enumerate(zip(image_list,features_list))):\n",
    "\n",
    "    if image_path in processed_items:\n",
    "        continue\n",
    "    processed_items.append(image_path)\n",
    "\n",
    "    most_similars = annoy_utils.query_similar_images_by_features(tmp_features, retrieve_n_most_similar)\n",
    "    \n",
    "    for sim_image_ind, confidence  in most_similars:\n",
    "        similar_image_path = image_list[sim_image_ind]\n",
    "        \n",
    "        if similar_image_path == image_path or similar_image_path in processed_items:\n",
    "            continue\n",
    "\n",
    "        if confidence < similarity_threshold: #0.0 exact match, <0.5 similar images\n",
    "            if image_path in similar_items:\n",
    "                similar_items[image_path].append([similar_image_path, confidence])\n",
    "            else:\n",
    "                similar_items[image_path] = []\n",
    "                similar_items[image_path].append([similar_image_path, confidence])\n",
    "            processed_items.append(similar_image_path)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_similar_items(similar_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete samples\n",
    "#### !set simulate=False to remove!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_similar_items(similar_items, simulate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
